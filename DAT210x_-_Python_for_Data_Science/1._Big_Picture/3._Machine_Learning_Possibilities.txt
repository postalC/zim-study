Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2016-10-14T21:56:42+08:00

====== 3. Machine Learning Possibilities ======
Created Friday 14 October 2016

Machine learning is a field that is actively being developed. As a programmer, you too can take part in that development. The traditional route of doing this starts by brushing up on all those mathematics and statistics courses you took in university, and maybe even going back to get a PhD. There are also many free online lectures you could benefit from, a few of which we've linked to in the Dive Deeper section. You could even try implementing a few of the simpler algorithms from scratch, such as K-Nearest Neighbors.

That said, the purpose of this course isn't to get you programming machine learning algorithms. Rather, it is only intended to introduce you to their usage, and get you comfortable with their application.

https://www.tensorflow.org/
Machine learning gets better by the day. Sometimes due to novel approaches being formulated, but usually due to our ability to process more data. Recently, Google open-sourced their flagship, deep-learning, neural-network library called TensorFlow. This is the software package in change of processing your third grade picture and telling you "pale child in shorts hugging a balloon". It's the algorithm Google uses to translate text back and forth between Arabic and Zulu. TensorFlow was responsible for beating Lee Sedol, the 9th-dan, world Go champion. And of course, TensorFlow is a critical part of Google's bread-and-butter search pipeline. Google open sourced this tool without much fear because it's really the data and not the algorithm that drives their killer insights. With enough good data—and we all know Google knows us better than our parents, siblings, and even spouses—it is simply amazing what you can get a computer to do.

Given good data, there are a few targeted areas where machine learning really shines. If you can engineer your data driven questions into one or more of these identified areas, you can take full advantage of all machine learning has to offer using out-of-the box algorithms. Take a look at this non-exhaustive list of sample areas, and try to find a pattern you can reformulate your ideas to conform to.


===== Classification (Supervised) =====
The goal of classification is to find what class a sample belongs to.

A class could be something like Windows 10 Mobile, and a sample could be something like phone. To get classification working, you have to feed the machine learning algorithm a decent amount phone examples, some of them labeled Windows 10 Mobile, and others labeled, well... non-Windows 10 Mobile. With enough training samples, a classifier will eventually be able to generalize what similarities constitute a Windows 10 Mobile phone and voilà, you've trained a computer to figure out phone types!

==== More Examples ====
* Given a list of emails marked spam and not-spam, figure out if a newly received message is actually spam or not.
* Given many images of your friends, perform facial recognition on a brand-new, never-before seen image of one of your friends.
* After being trained with a few books, decide which of the before seen authors wrote an article.
* Given a list of physical symptoms, determine what ailment a person has.

Classification falls into the realm of supervised learning because in order for it to work, you have to guide the computer by proving it with examples of correctly labeled records. Once you're done training the computer, you can test it by seeing how accurately it scores those records.


===== Regression (Supervised) =====
The goal of regression is to predict a continuous-valued feature associated with a sample. Continuous-valued meaning small changes in the input result in small changes in the output.

Imagine hiking from Portland, OR to Seattle, WA. As time progresses, your distance from Portland increases and your distance to Seattle decreases. Even though you stop for meals and to rest, these distance values transition smoothly. Throughout the course of your hiking, you never magically teleport a large distance. Instead, you smoothly and incrementally make your way step-by-step. With regression, a mathematical relationship is modeled for your samples so that as you gently alter one feature, another feature responds by being altered as well.
{{./Regression.png}}

==== More Examples ====
* Calculate an equation to predict the size of a house given its price; or the price of a house given its size.
* Explore if a correlation exists between hours a student spends studying, spends watching TV, and their final exam score.
* Estimate how many power plants should be constructed in the next 50 years, based upon the historical energy consumption per household.
* Figure out how many days a person has left to live based on the severity of their symptoms.

Regression falls into the realm of supervised learning because in order for it to work, you have to provide the computer with labeled samples. It then attempts to fit an equation to the samples' features.


===== Clustering (Unsupervised) =====
The goal of clustering is to automatically group similar samples into sets.

Since a clustering algorithm has no prior knowledge of how the sets should be defined, and furthermore, since the clustering process is unsupervised, the clustering algorithm needs to have a way to tell which samples are the most similar, so it can group them. It does this the same way we humans do: by looking at the various characteristics and features of the sample.
{{./Clustering.png}}

==== More Examples ====
* Match similar people on a matrimonial site based on their profile question answers.
* Based on search history, recommend houses a prospective home-buyer might be interested in considering.
* Pinpoint the most likely location for a future earthquake using past earthquake seismic data.
* Identify new characteristics shared by different people suffering from the same disease.

There are different types of clustering algorithms, some supervised, some unsupervised. There are even semi-supervised clustering methods as well. In this course, you'll only be dealing only with unsupervised clustering. In other words, the clustering algorithm you will use won't need anything except your raw data. No labels hinting at desired clustering outcome will be provided to the algorithm.


===== Dimensionality Reduction (Unsupervised) =====
The goal of dimensionality reduction is to systematically and intelligently reduce the number of features considered in a dataset. Stated differently, trim the fat off. Often times, in one's eagerness to collect enough data for machine learning to be effective, you might add irrelevant features to your dataset. Bad features have the effect of hindering the machine learning process, and make your data harder to understand. Dimensionality reduction attempts to trim your dataset down to the bare essentials needed for decision-making.
{{./DimenReduct.png}}

==== More Examples ====
* Given a 100 question survey, attempt to find the gist of what is truly being accessed; then rephrase it in just 5 questions.
* Build a robot that can recognize pictures of similar objects, even if they are rotated at odd angles and orientations.
* Compress a video stream by reducing the number of colors.
* Summarize a long book.

Dimensionality reduction falls into the realm of unsupervised learning because you don't instruct the computer which features you want it to build; the computer infers this information automatically by examining your unlabeled data.


===== Reinforcement Learning =====
The goal of reinforcement learning is to maximize a cumulative reward function (or equivalently, minimize a cumulative cost function), given a set of actions and results. Reinforcement learning is modeled to mimic the way we learn in the real world. We try to solve problems using different techniques. Most of the time, nothing of merit results from our experiments. But occasionally, we stumble upon a set of actions that result in a sweet reward. When this happens, we attempt to repeat these actions that will result in our getting rewarded. If we are rewarded yet again, we further associate those actions with the reward and that is known as the reinforcement cycle. The entire process is also known as performance maximization.
{{./RL.png}}

==== More Examples ====
* Discover how to fly a quadcopter by minimizing the function which evaluates the chances of crashing.
* Learn to beat a video game like 'Super Mario Bros.' by minimizing the time it takes to get to the castle.
* Attempt to take a photo and "re-draw" it in the style of a particular artist.
* Automate the trading of stocks and securities by maximizing profit and minimizing transaction fees.

Reinforcement learning is actually a completely different category of learning from supervised and unsupervised learning. It's closer to supervised learning than it is to unsupervised learning, but you could get away with calling it semi-supervised learning. To learn more about reinforcement learning, take a look at the dive deeper section. We won't return to reinforcement learning in this class, but it's important to be aware of it as a data scientist. Much work has been done using reinforcement learning and deep neural networks that are of benefit to machine learning.
